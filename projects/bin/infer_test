#!/usr/bin/env python
import sys
import os
import yaml
from semantic_selector import ml_model
from semantic_selector import datasource


def main():
    '''
        ./bin/infer_test [label grouping file]
    '''
    import yaml
    label_grouping = None
    if len(sys.argv) > 1 and os.path.exists(sys.argv[1]):
        path = sys.argv[1]
        with open(path) as f:
            label_grouping = yaml.load(f.read())

    # training data is auto loaded during LsiModel initialization
    model = ml_model.LsiModel(grouping=label_grouping, test_data_ratio=0.05)
    print("html, estimated, correct")
    positive_hit = 0
    unknown_hit = 0
    unknown_cnt = 0
    test_records = model.test_data
    for t in test_records:
        target_tag = t['html']
        estimated_label = model.inference_html(target_tag)
        correct_label = model.grouped_label_name(t['label'])
        if estimated_label != correct_label:
            print(t['html'].replace(',', '') +
                  ',' + estimated_label +
                  "," + correct_label)
        if correct_label == 'unknown':
            unknown_cnt += 1
        if estimated_label == correct_label:
            if correct_label == 'unknown':
                unknown_hit += 1
            else:
                positive_hit += 1

    print()
    print("# of test data: " + str(len(model.test_data)))
    print("# of training_data: " + str(len(model.answers)))
    print("Model Fitting Score,", model.fitting_score)
    print("Total Accuracy,", ((positive_hit + unknown_hit) / len(test_records)))
    print("Total Recall,", (positive_hit / (len(test_records) - unknown_cnt)))
    print("unkown ratio in test data,", (unknown_cnt / len(test_records)))

    datasource.InputTags.cleanup()


if __name__ == '__main__':
    main()
